{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slump Test Dataset Study\n",
    "\n",
    "this analysis were done using ADALINE Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from codes.input_treatment import prepare_dataset_data\n",
    "\n",
    "\n",
    "with open(\"datasets/slump_test.csv\", newline=\"\\n\") as csvfile:\n",
    "    num_of_tests = 30\n",
    "    error_history = []\n",
    "\n",
    "    (trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels, test_dataset_labels\n",
    "        ) = prepare_dataset_data(csvfile, range(8), range(8, 11), ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for slump prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.adaline import fit, predict\n",
    "\n",
    "from codes.common import shuffle_lists\n",
    "\n",
    "\n",
    "num_of_tests = 30\n",
    "tests_error_history = []\n",
    "\n",
    "for i in range(num_of_tests):\n",
    "        shuffle_lists(trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels[0], test_dataset_labels[0])\n",
    "\n",
    "        weights = fit(test_dataset_inputs, test_dataset_labels[0], 0.0000005, 50000)\n",
    "\n",
    "        predictions = [predict(input, weights) for input in test_dataset_inputs]\n",
    "        errors = [abs(l - p) for (p, l) in zip(predictions, test_dataset_labels[0])]\n",
    "        tests_error_history.append(sum(errors)/len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tests done: 30\n",
      "average error were: 0.002982075039710866 cm\n",
      "standard deviation: 0.0006780444520167823 cm\n"
     ]
    }
   ],
   "source": [
    "from codes.common import calc_average, calc_standard_deviation\n",
    "\n",
    "average_error = calc_average(tests_error_history)\n",
    "standard_deviation = calc_standard_deviation(tests_error_history, average_error)\n",
    "\n",
    "print(\"\\ntests done:\", num_of_tests)\n",
    "print(\"average error were:\", average_error, \"cm\")\n",
    "print(\"standard deviation:\", standard_deviation, \"cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for flow prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.adaline import fit, predict\n",
    "\n",
    "from codes.common import shuffle_lists\n",
    "\n",
    "\n",
    "num_of_tests = 30\n",
    "tests_error_history = []\n",
    "\n",
    "for i in range(num_of_tests):\n",
    "        shuffle_lists(trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels[1], test_dataset_labels[1])\n",
    "\n",
    "        weights = fit(test_dataset_inputs, test_dataset_labels[0], 0.0000005, 5000000)\n",
    "\n",
    "        predictions = [predict(input, weights) for input in test_dataset_inputs]\n",
    "        errors = [abs(l - p) for (p, l) in zip(predictions, test_dataset_labels[1])]\n",
    "        tests_error_history.append(sum(errors)/len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tests done: 30\n",
      "average error were: 10.62666666666268 cm\n",
      "standard deviation: 1.3619920006628187e-12 cm\n"
     ]
    }
   ],
   "source": [
    "from codes.common import calc_average, calc_standard_deviation\n",
    "\n",
    "average_error = calc_average(tests_error_history)\n",
    "standard_deviation = calc_standard_deviation(tests_error_history, average_error)\n",
    "\n",
    "print(\"\\ntests done:\", num_of_tests)\n",
    "print(\"average error were:\", average_error, \"cm\")\n",
    "print(\"standard deviation:\", standard_deviation, \"cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for 28-day Compressive Strength prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.adaline import fit, predict\n",
    "\n",
    "from codes.common import shuffle_lists\n",
    "\n",
    "\n",
    "num_of_tests = 30\n",
    "tests_error_history = []\n",
    "\n",
    "for i in range(num_of_tests):\n",
    "        shuffle_lists(trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels[2], test_dataset_labels[2])\n",
    "\n",
    "        weights = fit(test_dataset_inputs, test_dataset_labels[0], 0.0000005, 50000)\n",
    "\n",
    "        predictions = [predict(input, weights) for input in test_dataset_inputs]\n",
    "        errors = [abs(l - p) for (p, l) in zip(predictions, test_dataset_labels[2])]\n",
    "        tests_error_history.append(sum(errors)/len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tests done: 30\n",
      "average error were: 8.46835553394668 Mpa\n",
      "standard deviation: 0.0003956928434825239 Mpa\n"
     ]
    }
   ],
   "source": [
    "from codes.common import calc_average, calc_standard_deviation\n",
    "\n",
    "average_error = calc_average(tests_error_history)\n",
    "standard_deviation = calc_standard_deviation(tests_error_history, average_error)\n",
    "\n",
    "print(\"\\ntests done:\", num_of_tests)\n",
    "print(\"average error were:\", average_error, \"Mpa\")\n",
    "print(\"standard deviation:\", standard_deviation, \"Mpa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
