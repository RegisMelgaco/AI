{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portas de Limiar\n",
    "\n",
    "É a soma ponderada de um certo numero de entradas (que podem ser 0 ou 1) ponderadas a certo valor de limiar, caso seja menor retorna zero, se não retorna 1.\n",
    "\n",
    "## P. L. Linear\n",
    "\n",
    "Porta limiar que faz o somatório de cada entrada multiplcada a seu respectivo peso, caso seja menor retorna zero, se não retorna 1.\n",
    "\n",
    "## P. L. Quadratica\n",
    "\n",
    "Tem o mesmo funcionamento da PLL, com o acrescimo de pesos para todas as combinações possiveis de duas entradas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, shuffle\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class PerceptronNeuron:\n",
    "\n",
    "    def __init__ (self, input_size, learning_rate, initial_max_weight, initial_min_weight, max_age = 10000):\n",
    "        self.weights = self.gen_weights(input_size, initial_min_weight, initial_max_weight)\n",
    "        self.bias = self.gen_bias(initial_min_weight, initial_max_weight)\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.age, self.max_age = 0, max_age\n",
    "\n",
    "    def gen_weights(self, input_size, min_weight, max_weight):\n",
    "        weights = []\n",
    "        for i in range(1, input_size+1):\n",
    "            weights.append([randint (min_weight, max_weight) for j in range(i)]) \n",
    "        return weights\n",
    "\n",
    "    def gen_bias(self, min_weight, max_weight):\n",
    "        return randint (min_weight, max_weight)\n",
    "\n",
    "    def activation (self, input):\n",
    "        acc = self.bias\n",
    "        for (row, w_row) in enumerate(self.weights):\n",
    "            for (col, weight) in enumerate(w_row):\n",
    "                acc += weight * input[row] if row == col else weight * input[row] * input[col]\n",
    "        return acc\n",
    "\n",
    "    def update_weights(self, input, error):\n",
    "        for row in range(len(self.weights)):\n",
    "            for col in range(len(self.weights[row])):\n",
    "                if row == col:\n",
    "                    self.weights[row][col] += input[row] * error * self.learning_rate\n",
    "                else:\n",
    "                    self.weights[row][col] += input[row] * input[col] * error * self.learning_rate\n",
    "\n",
    "    def update_bias(self, error):\n",
    "        self.bias += self.learning_rate * error\n",
    "\n",
    "    def fit (self, inputs, labels):\n",
    "        loops_since_last_error = 0\n",
    "        cases = [{'input': i + [1], 'label': l} for (i, l) in zip(inputs , labels)]\n",
    "        self.age, i = 0, 0\n",
    "\n",
    "        while loops_since_last_error < len(cases) and self.max_age >= self.age:\n",
    "            error = cases[i]['label'] - self.predict(cases[i]['input'])\n",
    "\n",
    "            if error != 0:\n",
    "                loops_since_last_error = 0\n",
    "                self.update_weights(cases[i]['input'], error)\n",
    "                self.update_bias(error)\n",
    "            else:\n",
    "                loops_since_last_error += 1\n",
    "            \n",
    "            self.age += 1\n",
    "            i = self.age % len(cases)\n",
    "            if self.age == 0: shuffle(cases)\n",
    "\n",
    "    def predict (self, input):\n",
    "        return 1.0 if self.activation(input) >= 0.0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema da Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== setosa ===\n",
      "taxa de acerto: 1.0\n",
      "contagem de eras: 30007\n",
      "=== versicolor ===\n",
      "taxa de acerto: 0.9666666666666667\n",
      "contagem de eras: 1000001\n",
      "=== virginica ===\n",
      "taxa de acerto: 0.975\n",
      "contagem de eras: 1000001\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from codes.simple_perceptron import PerceptronNeuron\n",
    "from functools import reduce\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "with open(\"datasets/iris.csv\", newline=\"\\n\") as csvfile:\n",
    "    irirs_dataset = reduce(lambda acc, case: acc + [case], csv.reader(csvfile, delimiter = \",\"), [])\n",
    "    shuffle(irirs_dataset)\n",
    "    dataset_input = []\n",
    "    dataset_labels = {\"setosa\": [], \"versicolor\": [], \"virginica\": []}\n",
    "\n",
    "    for [sepal_length, sepal_width, petal_length, petal_width, spicie] in irirs_dataset:\n",
    "        dataset_input.append(list(map(float, [sepal_length, sepal_width, petal_length, petal_width])))\n",
    "\n",
    "        dataset_labels[\"setosa\"].append(1 if spicie == \"Iris-setosa\" else 0)\n",
    "        dataset_labels[\"versicolor\"].append(1 if spicie == \"Iris-versicolor\" else 0)\n",
    "        dataset_labels[\"virginica\"].append(1 if spicie == \"Iris-virginica\" else 0)\n",
    "\n",
    "    dataset_input_size = len(dataset_input[0])\n",
    "    dataset_size = len(dataset_input)\n",
    "\n",
    "    test_dataset_input = dataset_input[int(dataset_size*0.2):]\n",
    "    test_dataset_labels = {\"setosa\": dataset_labels[\"setosa\"][int(dataset_size*0.2):],\n",
    "                           \"versicolor\": dataset_labels[\"versicolor\"][int(dataset_size*0.2):],\n",
    "                           \"virginica\": dataset_labels[\"virginica\"][int(dataset_size*0.2):]}\n",
    "\n",
    "    trainig_dataset_input = dataset_input[:int(dataset_size*0.8)]\n",
    "    trainig_dataset_labels = {\"setosa\": dataset_labels[\"setosa\"][:int(dataset_size*0.8)],\n",
    "                              \"versicolor\": dataset_labels[\"versicolor\"][:int(dataset_size*0.8)],\n",
    "                              \"virginica\": dataset_labels[\"virginica\"][:int(dataset_size*0.8)]}\n",
    "\n",
    "    neurons = {\"setosa\": PerceptronNeuron(dataset_input_size, 0.0001, 10, -10, 1000000),\n",
    "               \"versicolor\": PerceptronNeuron(dataset_input_size, 0.0001, 10, -10, 1000000),\n",
    "               \"virginica\": PerceptronNeuron(dataset_input_size, 0.0001, 10, -10, 1000000)}\n",
    "\n",
    "    neurons[\"setosa\"].fit(trainig_dataset_input, trainig_dataset_labels[\"setosa\"])\n",
    "    neurons[\"versicolor\"].fit(trainig_dataset_input, trainig_dataset_labels[\"versicolor\"])\n",
    "    neurons[\"virginica\"].fit(trainig_dataset_input, trainig_dataset_labels[\"virginica\"])\n",
    "\n",
    "\n",
    "    print(\"=== setosa ===\")\n",
    "    correct_cases = 0\n",
    "    for (input, label) in zip(test_dataset_input, test_dataset_labels[\"setosa\"]):\n",
    "        correct_cases += 1 if label == neurons[\"setosa\"].predict(input) else 0\n",
    "\n",
    "    print(\"taxa de acerto:\", correct_cases/len(test_dataset_input))\n",
    "    print(\"contagem de eras:\", neurons[\"setosa\"].age)\n",
    "\n",
    "    print(\"=== versicolor ===\")\n",
    "    correct_cases = 0\n",
    "    for (input, label) in zip(test_dataset_input, test_dataset_labels[\"versicolor\"]):\n",
    "        correct_cases += 1 if label == neurons[\"versicolor\"].predict(input) else 0\n",
    "\n",
    "    print(\"taxa de acerto:\", correct_cases/len(test_dataset_input))\n",
    "    print(\"contagem de eras:\", neurons[\"versicolor\"].age)\n",
    "\n",
    "    print(\"=== virginica ===\")\n",
    "    correct_cases = 0\n",
    "    for (input, label) in zip(test_dataset_input, test_dataset_labels[\"virginica\"]):\n",
    "        correct_cases += 1 if label == neurons[\"virginica\"].predict(input) else 0\n",
    "\n",
    "    print(\"taxa de acerto:\", correct_cases/len(test_dataset_input))\n",
    "    print(\"contagem de eras:\", neurons[\"virginica\"].age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema da Porta XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== test ===\n",
      "[0, 0] -> 0.0\n",
      "[0, 1] -> 1.0\n",
      "[1, 0] -> 1.0\n",
      "[1, 1] -> 0.0\n"
     ]
    }
   ],
   "source": [
    "pn = PerceptronNeuron(2, 0.5, 2, -2, 1000)\n",
    "\n",
    "inputs = [[x1, x2] for x1 in range(2) for x2 in range(2)]\n",
    "labels = [0,1,1,0]\n",
    "\n",
    "pn.fit(inputs, labels)\n",
    "\n",
    "print(\"=== test ===\")\n",
    "for input in inputs:\n",
    "    print(input, \"->\", pn.predict(input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
