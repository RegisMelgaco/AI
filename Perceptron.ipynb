{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portas de Limiar\n",
    "\n",
    "É a soma ponderada de um certo numero de entradas (que podem ser 0 ou 1) ponderadas a certo valor de limiar, caso seja menor retorna zero, se não retorna 1.\n",
    "\n",
    "## P. L. Linear\n",
    "\n",
    "Porta limiar que faz o somatório de cada entrada multiplcada a seu respectivo peso, caso seja menor retorna zero, se não retorna 1.\n",
    "\n",
    "## P. L. Quadratica\n",
    "\n",
    "Tem o mesmo funcionamento da PLL, com o acrescimo de pesos para todas as combinações possiveis de duas entradas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, shuffle\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "\n",
    "class PerceptronNeuron:\n",
    "\n",
    "    def __init__ (self, input_size, learning_rate, initial_max_weight, initial_min_weight, max_age = 10000):\n",
    "        self.weights = [randint (initial_min_weight, initial_max_weight) for i in range(input_size + 1)]\n",
    "        self.input_size = input_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.age, self.max_age = 0, max_age\n",
    "\n",
    "    def insure_bias_input(self, input):\n",
    "        return input[:] if len(input) == self.input_size + 1 else input + [1]\n",
    "\n",
    "    def activation (self, input):\n",
    "        input = self.insure_bias_input(input)\n",
    "        acc = 0\n",
    "        for (x, w) in zip(input, self.weights):\n",
    "            acc += x * w\n",
    "        return acc\n",
    "\n",
    "    def fit (self, inputs, labels):\n",
    "        loops_since_last_error = 0\n",
    "        cases = [{'input': i + [1], 'label': l} for (i, l) in zip(inputs , labels)]\n",
    "        self.age, i = 0, 0\n",
    "\n",
    "        while loops_since_last_error < len(cases) and self.max_age >= self.age:\n",
    "            error = cases[i]['label'] - self.predict(cases[i]['input'])\n",
    "\n",
    "            if error != 0:\n",
    "                loops_since_last_error = 0\n",
    "                self.update_weights(cases[i]['input'], error)\n",
    "            else:\n",
    "                loops_since_last_error += 1\n",
    "            \n",
    "            self.age += 1\n",
    "            i = self.age % len(cases)\n",
    "            if self.age == 0: shuffle(cases)\n",
    "\n",
    "    def update_weights(self, input, error):\n",
    "        for (j, coordenate) in enumerate(input):\n",
    "            self.weights[j] += self.learning_rate * error * coordenate\n",
    "\n",
    "    def predict (self, input):\n",
    "        return 1.0 if self.activation(input) >= 0.0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto: 1.0\n",
      "contagem de eras: 155\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from functools import reduce\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "with open(\"datasets/iris.csv\", newline=\"\\n\") as csvfile:\n",
    "    irirs_dataset = reduce(lambda acc, case: acc + [case], csv.reader(csvfile, delimiter = \",\"), [])\n",
    "    shuffle(irirs_dataset)\n",
    "    dataset_input, dataset_labels = [], []\n",
    "\n",
    "    for [sepal_length, sepal_width, petal_length, petal_width, spicie] in irirs_dataset:\n",
    "        dataset_input.append(list(map(float, [sepal_length, sepal_width, petal_length, petal_width])))\n",
    "        dataset_labels.append(1 if spicie == \"Iris-setosa\" else 0)\n",
    "    \n",
    "    dataset_input_size = len(dataset_input[0])\n",
    "    dataset_size = len(dataset_input)\n",
    "\n",
    "    trainig_dataset_input, trainig_dataset_labels = dataset_input[:int(dataset_size*0.8)], dataset_labels[:int(dataset_size*0.8)]\n",
    "    test_dataset_input, test_dataset_labels = dataset_input[int(dataset_size*0.8):], dataset_labels[int(dataset_size*0.8):]\n",
    "\n",
    "    sp = PerceptronNeuron(dataset_input_size, 0.1, 10, -10)\n",
    "    sp.fit(trainig_dataset_input, trainig_dataset_labels)\n",
    "\n",
    "    correct_cases = 0\n",
    "    for (input, label) in zip(test_dataset_input, test_dataset_labels):\n",
    "        correct_cases += 1 if label == sp.predict(input) else 0\n",
    "\n",
    "    print(\"taxa de acerto:\", correct_cases/len(test_dataset_input))\n",
    "    print(\"contagem de eras:\", sp.age)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
