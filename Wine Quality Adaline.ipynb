{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from functools import reduce\n",
    "from random import shuffle\n",
    "\n",
    "from codes.adaline import fit, predict\n",
    "\n",
    "\n",
    "def prepare_dataset_data(dataset, training_size_percentage = 0.8):\n",
    "    dataset_divisor = round(training_size_percentage * len(dataset))\n",
    "\n",
    "    trainig_dataset = dataset[:dataset_divisor]\n",
    "    test_dataset = dataset[dataset_divisor:]\n",
    "    \n",
    "    trainig_dataset_inputs = reduce(lambda acc, case: acc + [case[:-1]], trainig_dataset, [])\n",
    "    test_dataset_inputs = reduce(lambda acc, case: acc + [case[:-1]], test_dataset, [])\n",
    "    trainig_dataset_labels = reduce(lambda acc, case: acc + [case[-1]], trainig_dataset, [])\n",
    "    test_dataset_labels = reduce(lambda acc, case: acc + [case[-1]], test_dataset, [])\n",
    "\n",
    "    return (trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels, test_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== red wine ===\n",
      "number of tests: 30\n",
      "average error: 0.5179850676724678\n",
      "standard deviation: 0.028620360484858567\n"
     ]
    }
   ],
   "source": [
    "print(\"=== red wine ===\")\n",
    "with open(\"datasets/winequality-red.csv\", newline=\"\\n\") as csvfile:\n",
    "    untreated_dataset = reduce(lambda acc, case: acc + [case], csv.reader(csvfile, delimiter = \";\"), [])\n",
    "    dataset = [list(map(float, row)) for row in untreated_dataset]\n",
    "    num_of_tests = 30\n",
    "    error_history = []\n",
    "\n",
    "    for i in range(num_of_tests):\n",
    "        shuffle(dataset)\n",
    "        (trainig_dataset_inputs,test_dataset_inputs, trainig_dataset_labels, test_dataset_labels) = prepare_dataset_data(dataset)\n",
    "\n",
    "        test_dataset_labels_len = len(test_dataset_labels)\n",
    "\n",
    "        weights = fit(test_dataset_inputs, test_dataset_labels, 0.00005, 10000)\n",
    "        # print(weights)\n",
    "\n",
    "        predictions = [predict(input, weights) for input in test_dataset_inputs]\n",
    "        errors = [abs(l - p) for (p, l) in zip(predictions, test_dataset_labels)]\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        error_history.append(average_error)\n",
    "\n",
    "    average_accurace = sum(error_history) / len(error_history)\n",
    "    standard_deviation = reduce(lambda acc, accuracy: acc + abs(average_accurace-accuracy), error_history, 0)/len(error_history)\n",
    "\n",
    "    print(\"number of tests:\", num_of_tests)\n",
    "    print(\"average error:\", average_accurace)\n",
    "    print(\"standard deviation:\", standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== white wine ===\n",
      "number of tests: 30\n",
      "average error: 1.012433587560307\n",
      "standard deviation: 0.44060151424914096\n"
     ]
    }
   ],
   "source": [
    "print(\"=== white wine ===\")\n",
    "with open(\"datasets/winequality-white.csv\", newline=\"\\n\") as csvfile:\n",
    "    untreated_dataset = reduce(lambda acc, case: acc + [case], csv.reader(csvfile, delimiter = \";\"), [])\n",
    "    dataset = [list(map(float, row)) for row in untreated_dataset]\n",
    "    num_of_tests = 30\n",
    "    error_history = []\n",
    "\n",
    "    for i in range(num_of_tests):\n",
    "        shuffle(dataset)\n",
    "        (trainig_dataset_inputs,test_dataset_inputs, trainig_dataset_labels, test_dataset_labels) = prepare_dataset_data(dataset)\n",
    "\n",
    "        test_dataset_labels_len = len(test_dataset_labels)\n",
    "\n",
    "        weights = fit(test_dataset_inputs, test_dataset_labels, 0.00005, 10000)\n",
    "\n",
    "        predictions = [predict(input, weights) for input in test_dataset_inputs]\n",
    "        errors = [abs(l - p) for (p, l) in zip(predictions, test_dataset_labels)]\n",
    "        average_error = sum(errors)/len(errors)\n",
    "        error_history.append(average_error)\n",
    "\n",
    "    average_accurace = sum(error_history) / len(error_history)\n",
    "    standard_deviation = reduce(lambda acc, accuracy: acc + abs(average_accurace-accuracy), error_history, 0)/len(error_history)\n",
    "\n",
    "    print(\"number of tests:\", num_of_tests)\n",
    "    print(\"average error:\", average_accurace)\n",
    "    print(\"standard deviation:\", standard_deviation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
