{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of confusion matrixes: 30\n",
      "average accurace: 0.8822222222222222\n",
      "standard deviation: 0.06474074074074077\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from functools import reduce\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from codes.uni_layer_perceptron import fit, predict\n",
    "\n",
    "\n",
    "# last col must be the label\n",
    "def prepare_dataset_data(dataset, training_size_percentage = 0.8):\n",
    "    dataset_divisor = round(training_size_percentage * len(dataset))\n",
    "    trainig_dataset = dataset[:dataset_divisor]\n",
    "    test_dataset = dataset[dataset_divisor:]\n",
    "    \n",
    "    trainig_dataset_inputs = reduce(lambda acc, case: acc + [case[:-1]], trainig_dataset, [])\n",
    "    test_dataset_inputs = reduce(lambda acc, case: acc + [case[:-1]], test_dataset, [])\n",
    "    trainig_dataset_labels = reduce(lambda acc, case: acc + [case[-1]], trainig_dataset, [])\n",
    "    test_dataset_labels = reduce(lambda acc, case: acc + [case[-1]], test_dataset, [])\n",
    "\n",
    "    return (trainig_dataset_inputs, test_dataset_inputs, trainig_dataset_labels, test_dataset_labels)\n",
    "\n",
    "with open(\"datasets/iris.csv\", newline=\"\\n\") as csvfile:\n",
    "    untreated_irirs_dataset = reduce(lambda acc, case: acc + [case], csv.reader(csvfile, delimiter = \",\"), [])\n",
    "    classes = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "    iris_dataset = list(map(lambda row: row[:-1]+[classes[row[-1]]], untreated_irirs_dataset))\n",
    "    iris_dataset = [list(map(float, row)) for row in iris_dataset]\n",
    "    confusion_matrix_history = []\n",
    "    test_dataset_labels_len = 0\n",
    "    num_of_tests = 30\n",
    "\n",
    "    for i in range(num_of_tests):\n",
    "        shuffle(iris_dataset)\n",
    "        (trainig_dataset_inputs,test_dataset_inputs, trainig_dataset_labels, test_dataset_labels) = prepare_dataset_data(iris_dataset)\n",
    "\n",
    "        test_dataset_labels_len = len(test_dataset_labels)\n",
    "\n",
    "        weights_list = fit(test_dataset_inputs, test_dataset_labels, 3, 0.005, 10000)\n",
    "\n",
    "        predictions = [predict(input, weights_list) for input in test_dataset_inputs]\n",
    "        cf = confusion_matrix(test_dataset_labels, predictions)\n",
    "        confusion_matrix_history.append(cf)\n",
    "\n",
    "    matrix_diagonal = lambda matrix: [matrix[i][i] for i in range(len(matrix))]\n",
    "    calc_accuracy = lambda confusion_matrix, cases_count: sum(matrix_diagonal(confusion_matrix))/cases_count\n",
    "\n",
    "    accuracy_history = [calc_accuracy(cm, test_dataset_labels_len) for cm in confusion_matrix_history]\n",
    "    average_accurace = sum(accuracy_history) / len(accuracy_history)\n",
    "    standard_deviation = reduce(lambda acc, accuracy: acc + abs(average_accurace-accuracy), accuracy_history, 0)/len(accuracy_history)\n",
    "\n",
    "    print(\"number of confusion matrixes:\", len(confusion_matrix_history))\n",
    "    print(\"average accurace:\", average_accurace)\n",
    "    print(\"standard deviation:\", standard_deviation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
